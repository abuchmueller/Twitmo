---
output: github_document
---

```{r echo=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-"
)
options(width = 100)
library(Twitmo)
```

# Twitmo <img src="man/figures/hexSticker.png" width="160px" align="right" />

<!-- badges: start -->
[![R-CMD-check](https://github.com/abuchmueller/Twitmo/workflows/R-CMD-check/badge.svg)](https://github.com/abuchmueller/Twitmo/actions)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
<!-- badges: end -->

The goal of `Twitmo` is to facilitate topic modeling in R with Twitter data. `Twitmo` provides a broad range of methods to sample, pre-process and visualize Tweets to make modeling the public discourse easy and accessible. This `README` covers the most important features. For more details use `vignette("Twitmo")`.

## Installation

You can install `Twitmo` from CRAN with:

```{r cran-installation, eval=FALSE}
install.packages("Twitmo")
```

You can install `Twitmo` from github with:

Before you install from Github make sure you have Rtools for [Windows](https://cran.r-project.org/bin/windows/Rtools/ "Rtools for Windows (CRAN)") or [macOS](https://thecoatlessprofessor.com/programming/cpp/r-compiler-tools-for-rcpp-on-macos/ "Rtools for macOS") already installed.

```{r gh-installation, eval = FALSE}
## install remotes package if it's not already
if (!requireNamespace("remotes", quietly = TRUE)) {
  install.packages("remotes")
}

## install dev version of Twitmo from github
remotes::install_github("abuchmueller/Twitmo")
```

## Example: Collect your tweets

Make sure you have a regular Twitter Account before start to sample your Tweets.

```{r eval=FALSE}
# Live stream Tweets from the UK for 30 seconds and save to "uk_tweets.json" in current working directory
get_tweets(method = 'stream', 
           location = "GBR", 
           timeout = 30, 
           file_name = "uk_tweets.json")

# Use your own bounding box to stream US mainland Tweets
get_tweets(method = 'stream', 
           location =   c(-125, 26, -65, 49), 
           timeout = 30,
           file_name = "tweets_from_us_mainland.json")
```

## Parse your tweets from a json file

```{r}
dat <- load_tweets("inst/extdata/tweets_20191027-141233.json")
```

## Pool tweets into document pools

```{r}
pool <- pool_tweets(dat)
pool.corpus <- pool$corpus
```

```{r}
pool.dfm <- pool$document_term_matrix
```

## Find optimal number of topics

```{r ldatuner}
find_lda(pool.dfm)
```

## Fit LDA model

```{r}
model <- fit_lda(pool.dfm, n_topics = 3)
```

## View most relevant terms for each topic

```{r}
lda_terms(model)
```

or which hashtags are heavily associated with each topic

```{r}
lda_hashtags(model)
```

## LDA Distribution

Check the distribution of your LDA Model with

```{r}
lda_distribution(model)
```

## Visualize with `LDAvis`

Make sure you have `servr` package installed.

```{r, eval=FALSE}
to_ldavis(model, pool.corpus, pool.dfm)
```
