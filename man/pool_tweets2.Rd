% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pool_tweets2.R
\name{pool_tweets2}
\alias{pool_tweets2}
\title{Prepare for Tweets for topic modeling by pooling (experimental)}
\usage{
pool_tweets(data, tokenizer = tokenizers::tokenize_tweets())
}
\arguments{
\item{data}{Data frame of parsed tweets. Obtained either by using \code{load_tweets()} or
\code{jsonlite::stream_in()} in conjunction with \code{rtweet::tweets_with_users(s)}.
See \link[TweetLocViz]{load_tweets} for details.}

\item{TFUN}{A tokenizer function of your choice e.g. \code{tokenizers::tokenize_tweets()}.
First argument of your tokenizer must be character vector or a list of character vectors to be tokenized.
External tokenizers have to be compatible to the quanteda See \link[quanteda]{tokens} constructor,
i.e. must output one of the following: a (uniquely) named list of characters;
a \link[quanteda]{tokens} object; or a See \link[quanteda]{corpus} or \link[base]{character} object to be tokenized.}

\item{cosine_threshold}{Double. Value between 0 and 1 specifying the cosine similarity used
for document pooling. Tweets without a hashtag will be assigned to document (hashtag) pools
based upon this metric. Low thresholds will reduce topic coherence by including
a large number of tweets without a hashtag into the document pools. Higher thresholds will lead
to more coherent topics but will reduce document sizes.}

\item{min_pool_size}{(NOT IMPLEMENTED) Integer value specifying the minimum size of document pools.
Document pools with less tweets than specified will be excluded from the corpus.
Defaults to 1 where every hashtag is a document pool. Large pools lead to more coherent topics
but will need larger sample sizes (i.e. more tweets) to work.}
}
\value{
List with corpus object and \link[quanteda]{dfm} object of pooled tweets.
}
\description{
This version of \link[TweetLocViz]{pool_tweets} allows the use of
external tokenizers.
}
\details{
This function pools a data frame of parsed tweets into document pools.
}
